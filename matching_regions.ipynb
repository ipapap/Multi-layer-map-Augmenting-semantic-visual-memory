{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **APPLYING LEIDEN ALGORITHM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import leidenalg\n",
    "import igraph as ig\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import scipy.io\n",
    "from sklearn.neighbors import NearestNeighbors \n",
    "dataset='sunny'   #change dataset here !!!"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "metric_X=np.zeros((n_metric_Clusters,1),dtype='float')\n",
    "for i in range(0,n_metric_Clusters) :\n",
    "    metric_X[i]=x[f==i]\n",
    "    metric_Y[i]=y[f==i]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# import numpy as np\n",
    "Xavg=np.zeros((n_DivClusters,1),dtype='float')\n",
    "Yavg=np.zeros((n_DivClusters,1),dtype='float')\n",
    "for i in range(1,n_DivClusters+1):\n",
    "    Xavg[i-1]=np.mean(x[part_final[i]])\n",
    "    Yavg[i-1]=np.mean(y[part_final[i]])\n",
    "        \n",
    "print(Xavg)\n",
    "print(Yavg)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "metric_Xavg=np.zeros((n_metric_Clusters,1),dtype='float')\n",
    "metric_Yavg=np.zeros((n_metric_Clusters,1),dtype='float')\n",
    "for i in range(0,n_metric_Clusters):\n",
    "    metric_Xavg[i]=np.mean(x[f==i])\n",
    "    metric_Yavg[i]=np.mean(y[f==i])\n",
    "        \n",
    "print(metric_Xavg)\n",
    "print(metric_Yavg)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import math\n",
    "d=np.zeros((n_DivClusters,n_metric_Clusters),dtype='float')\n",
    "FC=np.zeros((n_DivClusters,1),dtype='int')\n",
    "for i in range(0,n_DivClusters):\n",
    "    for j in range(0,n_metric_Clusters):\n",
    "        d[i-1][j]=math.sqrt(sum((Xavg[i] - metric_Xavg[j])**2 ,(Yavg[i] - metric_Yavg[j])**2))\n",
    "    FC[i]=np.argmin(d[i-1])                     \n",
    "print(FC)\n",
    "fc=FC.tolist()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "new_part=np.zeros((n_metric_Clusters,1),int)\n",
    "new_part=new_part.tolist()\n",
    "for i in range(0,n_metric_Clusters):\n",
    "    print(i)\n",
    "    idx=np.argwhere(FC[:]==i)\n",
    "    idx=idx[:,0].tolist()\n",
    "    if(idx):\n",
    "        new_part[i]=part_final[idx[0]]\n",
    "        for p in idx[1:-1]:\n",
    "            new_part[i].extend(part_final[p])\n",
    "\n",
    "#del new_part[0]\n",
    "\n",
    "print(new_part)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "new_part=np.asarray(new_part)\n",
    "plt.figure(2) \n",
    "for i in range(0,n_metric_Clusters) :\n",
    " #   for j in range(0,len(new_part[i])):\n",
    "    #plt.figure(i)     \n",
    "    plt.scatter(x[new_part[i][:]],y[new_part[i][:]],alpha=0.99, label='True Position',cmap='Dark2')\n",
    "    print(\"/n cluster:\",i, \"    cointains:\" ,new_part[i][:])\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CLUSTERING USING OVERLAP**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---LOCALIZATION based on average descriptor---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.chdir(\"/home/hades/codes/leiden/cold\")\n",
    "mat = scipy.io.loadmat('%s_VideoTable_FR3_1_300_DEFAULT.mat'%dataset)\n",
    "#mat2 = scipy.io.loadmat('matrix_testing.mat') # FOR TESTING ONLY\n",
    "os.chdir(\"/home/hades/codes/leiden/localization/\")\n",
    "import cv2\n",
    "#I=cv2.imread('test.jpg')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load main dataset descriptors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptor=np.empty((len(f),98128),float)\n",
    "for i in range(0,len(f)-2):\n",
    "    descriptor[i]=mat['VideoTable_fr_300'][0][i][0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "descriptor2=np.empty((len(f),98128),float)\n",
    "for i in range(0,len(f)-2):\n",
    "    descriptor2[i]=mat2['VideoTable_fr_300'][0][i][0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "avg=np.empty((len(final_Clusters),98128),float)\n",
    "for i in range(0,len(final_Clusters)):\n",
    "    suma=np.sum(descriptor[final_Clusters[i][:]],axis=0)\n",
    "    #print(x)\n",
    "    l=len(final_Clusters[i][:])\n",
    "    avg[i]=suma/l\n",
    "    \n",
    "#den xreiazetai "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Localization with K-NN**\n",
    " \n",
    "**Finding test sample's nearest neighboors**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "descriptor_test=descriptor2[1]#225\n",
    "\n",
    "neigh = NearestNeighbors(n_neighbors=10)\n",
    "neigh.fit(descriptor) \n",
    "print(neigh.kneighbors(descriptor_test.reshape(1, -1))) \n",
    "closest=neigh.kneighbors(descriptor_test.reshape(1, -1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classifying based on closest neighbors cluster**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a=np.empty((len(final_Clusters),1),int).tolist()\n",
    "for i in range(0,len(final_Clusters)):\n",
    "    a[i]=np.asarray(final_Clusters[i])   \n",
    "    \n",
    "closest_vector=[]\n",
    "for k in closest[1][0]:\n",
    "    #print('k=',k)\n",
    "    for i in range(0,len(final_Clusters)):\n",
    "        #print(np.argwhere(k==final_Clusters[i]))\n",
    "        #print(np.nonzero(k==final_Clusters[i]))\n",
    "        if np.any(np.nonzero(k==final_Clusters[i])):\n",
    "            closest_vector.append(i)\n",
    "            #print(i)\n",
    "#print(closest_vector)    \n",
    "counter=np.zeros((len(final_Clusters),1),int)    \n",
    "for i in range(0,len(closest_vector)):\n",
    "    counter[closest_vector[i]]+=1\n",
    "print(counter)\n",
    "print(\"The test samlple is in cluster \" ,np.argmax(counter,axis=0)[0])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### END ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "edges in original graph : 1276003\nedges after removal : 62373\n11\ninteriation no  0 \n\nis nan\ninteriation no  1 \n\nis nan\ninteriation no  2 \n\nis nan\ninteriation no  3 \n\nis nan\ninteriation no  4 \n\nis nan\ninteriation no  5 \n\nis nan\ninteriation no  6 \n\nis nan\ninteriation no  7 \n\nis nan\ninteriation no  8 \n\nis nan\ninteriation no  9 \n\nis nan\ninteriation no  10 \n\nis nan\n[49, 52, 41, 0, 55, 22, 32, 96, 16, 21, 56]\n"
    }
   ],
   "source": [
    "#import cairocffi as cairo\n",
    "import math\n",
    "G1=G\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "print(\"edges in original graph :\", G1.ecount())\n",
    "edge_list=G1.es.select(weight_lt=300) \n",
    "G1.delete_edges(edge_list)\n",
    "print(\"edges after removal :\",G1.ecount())\n",
    "G1.closeness( normalized=True)\n",
    "#G1.evcent(directed=False,scale=True,weights=None,return_eigenvalue=False)\n",
    "total_score=[]\n",
    "\n",
    "best_centrality=[]\n",
    "print(len(final_Clusters))\n",
    "for i in range(0,len(final_Clusters)):\n",
    "    print('interiation no ',i,'\\n')\n",
    "    h=G1.subgraph(final_Clusters[i])\n",
    "    ig.plot(h)\n",
    "    temp_closeness=h.closeness(normalized=True)\n",
    "   # print(np.array(temp_closeness) , '\\n')\n",
    "    temp_betweeness=h.betweenness(vertices=None, directed=False, cutoff=None, weights=None)\n",
    "    #print(np.array(temp_betweeness),'\\n')\n",
    "    \n",
    "    total_score.append([])\n",
    "    nan_check=0\n",
    "    \n",
    "    if np.any(temp_closeness):\n",
    "        nan_check=math.isnan(temp_closeness[0])\n",
    "        print('is nan')\n",
    "    if(np.any(temp_closeness)) and not (nan_check) :\n",
    "        #print (temp_closeness)\n",
    "        \n",
    "        temp_closeness_norm=normalize(np.array(temp_closeness).reshape(-1,1),axis=0)\n",
    "        #print(temp_closeness)\n",
    "        temp_betweeness_norm=normalize(np.array(temp_closeness).reshape(-1,1),axis=0)\n",
    "    for k in range(0,len(final_Clusters[i])):\n",
    "        total_score[i].append(0.5*temp_closeness_norm[k]+0.5*temp_betweeness_norm[k])\n",
    "      #  print(total_score)\n",
    "    #print (total_score[i])\n",
    "    #print(temp_closeness)\n",
    "    if(np.any(temp_closeness)):\n",
    "        best_centrality.append(np.argmax(np.array(total_score[i])))\n",
    "    else:\n",
    "        best_centrality.append([])   \n",
    "#print(normalize(np.array(temp_closeness).reshape(-1,1),axis=0))\n",
    "print(best_centrality)\n",
    "best_frame=[]\n",
    "best_frame_descriptor=[]\n",
    "best_frame_local=[]\n",
    "for i in range(0,len(final_Clusters)):    \n",
    "    \n",
    "        #best_frame.append([])\n",
    "    best_frame.append(final_Clusters[i][best_centrality[i]])\n",
    "    best_frame_descriptor.append(descriptor[final_Clusters[i][best_centrality[i]]])#(descriptor[best_frame[i]])\n",
    "    best_frame_local.append(best_centrality[i])    \n",
    "        #best_frame[i].extend([i])\n",
    "    #else:\n",
    "    #    best_frame.append(-1)\n",
    "    #    best_frame_descriptor.append(-1)\n",
    "    # ( best_frame , cluster that belongs )\n",
    "    \n",
    "#best_frame\n",
    "#best_frame_descriptor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.io.savemat('/home/hades/codes/leiden/temp/best_frame_sunny.mat', mdict={'central': best_frame})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "429"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_Clusters[i][np.argmax(np.array([1,2,3]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "descriptor=0\n",
    "total_score=np.empty((0,0),int)\n",
    "mat=np.empty((0,0),int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Saving characteristic Frames from each dataset**###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('/home/hades/codes/leiden/cold/cendroids_dataset_%s_bestFrame' %dataset ,best_frame)\n",
    "np.save('/home/hades/codes/leiden/cold/cendroids_dataset_%s_bestFrame_descriptor.npy' %dataset ,best_frame_descriptor)\n",
    "np.save('/home/hades/codes/leiden/cold/cendroids_dataset_%s_bestFrame_local' %dataset ,best_frame_local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('/home/hades/codes/leiden/cold/%s_clusters.npy'%dataset ,final_Clusters, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "192"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "if dataset !='cloudy':\n",
    "    ytf\n",
    "\n",
    "mat=0\n",
    "descriptor=0\n",
    "sys.getsizeof(final_Clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/home/hades/codes/leiden/cold\")\n",
    "sunny_best_frame=np.load('cendroids_dataset_sunny_bestFrame.npy',allow_pickle=True)\n",
    "sunny_best_descriptor=np.load('/home/hades/codes/leiden/cold/cendroids_dataset_sunny_bestFrame_descriptor.npy',allow_pickle=True)\n",
    "cloudy_best_frame=np.load('cendroids_dataset_cloudy_bestFrame.npy',allow_pickle=True)\n",
    "cloudy_best_descriptor=np.load('/home/hades/codes/leiden/cold/cendroids_dataset_cloudy_bestFrame_descriptor.npy',allow_pickle=True)\n",
    "night_best_frame=np.load('cendroids_dataset_night_bestFrame.npy',allow_pickle=True)\n",
    "night_best_descriptor=np.load('/home/hades/codes/leiden/cold/cendroids_dataset_night_bestFrame_descriptor.npy',allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Matching clusters to cloudy (using cendroids)**###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**characteristic frames of cloudy dataset:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[ 218 1425  365  919  764  708  946   53  561]\n[ 438   52 1325 1584  545  155 1223  869 1345  309 1463]\n"
    },
    {
     "data": {
      "text/plain": "1.094031826842451"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(cloudy_best_frame)\n",
    "print(sunny_best_frame)\n",
    "from scipy.spatial import distance\n",
    "distance.euclidean(sunny_best_descriptor[1],cloudy_best_descriptor[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting cloudy images to new folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "already exist, skipping..\n"
    }
   ],
   "source": [
    "import shutil, os\n",
    "try:\n",
    "    os.chdir(\"/home/hades/codes/leiden/cold/dataset_cloudy/\")\n",
    "    files = []\n",
    "    name='img00000000'\n",
    "    Im=230\n",
    "    #os.mkdir('/home/hades/codes/leiden/cold/class_test1/')\n",
    "    for i in range (0,len(final_Clusters)):\n",
    "        #os.rmdir('/home/hades/codes/leiden/cold/class/%d'%i)\n",
    "        os.mkdir('/home/hades/codes/leiden/cold/class_test1/%d'%i)\n",
    "        files=[]\n",
    "        for  Im in final_Clusters[i]:\n",
    "            #name='img00000000'\n",
    "            #name=name[0:-len(str(Im+1))]+str(Im+1)\n",
    "            name=str(Im)\n",
    "            files.append(name)\n",
    "            print(name)\n",
    "    \n",
    "            \n",
    "           \n",
    "            for f in files:\n",
    "             \n",
    "                shutil.copy(\"%s.jpeg\"%f, '/home/hades/codes/leiden/cold/class_test1/%d'%i)\n",
    "except FileExistsError:\n",
    "    print(\"already exist, skipping..\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting descriptors from cloudy images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#strt!@\n",
    "\n",
    "import cv2   \n",
    "import glob\n",
    "desc=[]\n",
    "for i in range(0,len(final_Clusters)):\n",
    "    os.chdir(\"/home/hades/codes/leiden/cold/class_test1/%d\" %i)\n",
    "    desc.append([])\n",
    "    for filename in glob.glob('*.jpeg'):\n",
    "        img = cv2.imread(filename,0)\n",
    "        #cv2.imshow(\"wer\",img)\n",
    "        #cv2.waitKey(30)\n",
    "        \n",
    "        cv2.destroyAllWindows()\n",
    "        sift=cv2.xfeatures2d.SURF_create(hessianThreshold = 200)#6000\n",
    "# Find keypoints and descriptors directly\n",
    "        kp, des = sift.detectAndCompute(img,None)\n",
    "        desc[i].append(des)\n",
    "        #print(\"\\n\")\n",
    "#print(desc)\n",
    "#print(\"fvdfvd\")\n",
    "np.save('/home/hades/codes/leiden/cold/desc_small_temp2.npy',desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc=np.load('/home/hades/codes/leiden/cold/desc_small_temp2.npy',allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating descriptor pool for cloudy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'd_pool' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-203d7386e4dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_pool\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'd_pool' is not defined"
     ]
    }
   ],
   "source": [
    "len(d_pool[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_pool=[]\n",
    "cl_idx=[]\n",
    "counter=0\n",
    "for i in range(0,len(final_Clusters)):\n",
    "    #d_pool.append([])\n",
    "    for j in range(0,len(desc[i])):\n",
    "        #d_pool[i].append([])\n",
    "        if desc[i][j] is None:\n",
    "            continue\n",
    "        for k in range(0,len(desc[i][j])):\n",
    "            d_pool.append(desc[i][j][k])\n",
    "            counter+=1\n",
    "    cl_idx.append(counter)\n",
    "        \n",
    "#d_pool   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('/home/hades/codes/leiden/cold/case_study/d_idx.y'np,cl_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('/home/hades/codes/leiden/temp/d_pool_cold.npy',d_pool)\n",
    "np.save('/home/hades/codes/leiden/temp/cl_idx_cold.npy',cl_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_night=[2,1,0,4,6,3,5,5]\n",
    "gt_sunny=[3,4,0,2,6,5,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Night Re-loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(filename)\n",
    "img = cv2.imread(filename,0)\n",
    "print(len(img))\n",
    "sift=cv2.xfeatures2d.SURF_create(2000)\n",
    "kp, des = sift.detectAndCompute(img,None)\n",
    "print(sift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "####test with knn\n",
    "d_night=[]\n",
    "counter=0\n",
    "\n",
    "os.chdir(\"/home/hades/codes/leiden/cold/dataset_night/\")\n",
    "\n",
    "for i in night_best_frame:\n",
    "\n",
    "    for filename in glob.glob('*.jpeg'):\n",
    "        if int(filename[:-5])==i:\n",
    "            d_night.append([])\n",
    "            img = cv2.imread(filename,0)\n",
    "            sift=cv2.xfeatures2d.SURF_create(200)\n",
    "# Find keypoints and descriptors directly\n",
    "            kp, des = sift.detectAndCompute(img,None)\n",
    "            des.any()==[None]\n",
    "            d_night[counter].append(des)\n",
    "            counter+=1\n",
    "            print(\"\\n\")\n",
    "#print(d_sunny)\n",
    "\n",
    "\n",
    "\n",
    "d_pool_night=[]\n",
    "for i in range(0,len(night_best_frame)):\n",
    "    d_pool_night.append([])\n",
    "    for j in range(0,len(d_night[i])):\n",
    "        #d_pool_sunny[i].append([])\n",
    "      \n",
    "        for k in range(0,len(d_night[i][j])):\n",
    "            d_pool_night[i].append(d_night[i][j][k])\n",
    "        \n",
    "        \n",
    "len(d_pool_night[1])\n",
    "\n",
    "local_frame=np.load('/home/hades/codes/leiden/cold/cendroids_dataset_night_bestFrame_local.npy')\n",
    "neigh = NearestNeighbors(n_neighbors=2)\n",
    "neigh.fit(d_pool) \n",
    "vote=[]\n",
    "for i in range(0,len(night_best_frame)):\n",
    "    match=neigh.kneighbors(np.asarray(d_pool_night[i]))#.reshape(1, -1))\n",
    "    #print(match)\n",
    "    vote.append([])\n",
    "    for x in range(0,len(cl_idx)):\n",
    "        if match[1][0][0]<cl_idx[x]:\n",
    "            vote[i].append(x)\n",
    "            break\n",
    "#print(vote)\n",
    "            \n",
    "#np.save('/home/hades/codes/leiden/cold/vote_night.npy', vote)\n",
    "vote2=[]\n",
    "for i in range(0,len(vote)):\n",
    "    m=0\n",
    "    vote2.append([])\n",
    "    for j in range(0,len(vote[i])):\n",
    "       # print('night[%d] --> cloudy [%d]'%(i,(len(vote[i][j]))))\n",
    "        vote2[i].append(len(vote[i]))\n",
    "success=0\n",
    "night_match=[]\n",
    "for i in range(0,len(vote)):    \n",
    "    print('cloudy[%d] --> night[%d]'%((vote[i][0],i)))\n",
    "\n",
    "\n",
    "    \n",
    "#closest=neigh.kneighbors(descriptor_test.reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "del vote\n",
    "neigh = NearestNeighbors(n_neighbors=1)\n",
    "neigh.fit(np.array(d_pool)) \n",
    "print('i am here!')\n",
    "match=[]\n",
    "#for i in range(0,len(best_frame)):\n",
    "#    print('loop',i)\n",
    "#    match.append(neigh.kneighbors(np.asarray(features[i])))#.reshape(1, -1))\n",
    "#    print(match[i])\n",
    "vote=[]\n",
    "idx2=[]\n",
    "print(cl_idx)\n",
    "#print(idx2)\n",
    "for i in range(0,len(night_best_frame)):\n",
    "    match=neigh.kneighbors(np.asarray(d_pool_night[i]))#.reshape(1, -1))\n",
    "    #print(match)\n",
    "    vote.append([])\n",
    "    for j in range(0,len(match[1])):\n",
    "        for x in range(0,len(cl_idx)):\n",
    "            if match[1][j]<cl_idx[x]:\n",
    "                vote[i].append(x)\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_frequent(List): \n",
    "    dict = {} \n",
    "    count, itm = 0, '' \n",
    "    for item in reversed(List): \n",
    "        dict[item] = dict.get(item, 0) + 1\n",
    "        if dict[item] >= count : \n",
    "            count, itm = dict[item], item \n",
    "    return(itm) \n",
    "  \n",
    "\n",
    "for i in range(0,len(vote)):\n",
    "    print(most_frequent(vote[i])) \n",
    "os.chdir(\"/home/hades/codes/leiden/cold/case_study\")    \n",
    "np.save('night_match.npy',vote)      \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "vote"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sunny Re-loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "####test with knn\n",
    "d_sunny=[]\n",
    "counter=0\n",
    "\n",
    "os.chdir(\"/home/hades/codes/leiden/cold/dataset_sunny/\")\n",
    "\n",
    "for i in sunny_best_frame:\n",
    "\n",
    "    for filename in glob.glob('*.jpeg'):\n",
    "        if int(filename[:-5])==i:\n",
    "            d_sunny.append([])\n",
    "            img = cv2.imread(filename,0)\n",
    "            sift=cv2.xfeatures2d.SURF_create(hessianThreshold = 200)\n",
    "# Find keypoints and descriptors directly\n",
    "            kp, des = sift.detectAndCompute(img,None)\n",
    "            d_sunny[counter].append(des)\n",
    "            counter+=1\n",
    "            print(\"\\n\")\n",
    "#print(d_sunny)\n",
    "\n",
    "\n",
    "d_pool_sunny=[]\n",
    "for i in range(0,len(sunny_best_frame)):\n",
    "    d_pool_sunny.append([])\n",
    "    for j in range(0,len(d_sunny[i])):\n",
    "        #d_pool_sunny[i].append([])\n",
    "        for k in range(0,len(d_sunny[i][j])):\n",
    "            d_pool_sunny[i].append(d_sunny[i][j][k])\n",
    "        \n",
    "        \n",
    "len(d_pool_sunny[1])\n",
    "\n",
    "local_frame=np.load('/home/hades/codes/leiden/cold/cendroids_dataset_sunny_bestFrame_local.npy')\n",
    "neigh = NearestNeighbors(n_neighbors=2)\n",
    "neigh.fit(d_pool) \n",
    "vote=[]\n",
    "for i in range(0,len(sunny_best_frame)):\n",
    "    match=neigh.kneighbors(np.asarray(d_pool_sunny[i]))#.reshape(1, -1))\n",
    "    #print(match)\n",
    "    vote.append([])\n",
    "    for x in range(0,len(cl_idx)):\n",
    "        if match[1][0][0]<cl_idx[x]:\n",
    "            vote[i].append(x)\n",
    "            break\n",
    "print(vote)\n",
    "            \n",
    "#np.save('/home/hades/codes/leiden/cold/vote_night.npy', vote)\n",
    "vote2=[]\n",
    "for i in range(0,len(vote)):\n",
    "    m=0\n",
    "    vote2.append([])\n",
    "    for j in range(0,len(vote[i])):\n",
    "       # print('night[%d] --> cloudy [%d]'%(i,(len(vote[i][j]))))\n",
    "        vote2[i].append(len(vote[i]))\n",
    "success=0\n",
    "\n",
    "for i in range(0,len(vote)):    \n",
    "    print('cloudy[%d] --> sunny[%d]'%((vote[i][0],i)))\n",
    "\n",
    "#closest=neigh.kneighbors(descriptor_test.reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "del vote\n",
    "neigh = NearestNeighbors(n_neighbors=1)\n",
    "neigh.fit(np.array(d_pool)) \n",
    "print('i am here!')\n",
    "match=[]\n",
    "#for i in range(0,len(best_frame)):\n",
    "#    print('loop',i)\n",
    "#    match.append(neigh.kneighbors(np.asarray(features[i])))#.reshape(1, -1))\n",
    "#    print(match[i])\n",
    "vote=[]\n",
    "idx2=[]\n",
    "print(cl_idx)\n",
    "#print(idx2)\n",
    "for i in range(0,len(sunny_best_frame)):\n",
    "    match=neigh.kneighbors(np.asarray(d_pool_sunny[i]))#.reshape(1, -1))\n",
    "    #print(match)\n",
    "    vote.append([])\n",
    "    for j in range(0,len(match[1])):\n",
    "        for x in range(0,len(cl_idx)):\n",
    "            if match[1][j]<cl_idx[x]:\n",
    "                vote[i].append(x)\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_frequent(List): \n",
    "    dict = {} \n",
    "    count, itm = 0, '' \n",
    "    for item in reversed(List): \n",
    "        dict[item] = dict.get(item, 0) + 1\n",
    "        if dict[item] >= count : \n",
    "            count, itm = dict[item], item \n",
    "    return(itm) \n",
    "  \n",
    "\n",
    "for i in range(0,len(vote)):\n",
    "    print(most_frequent(vote[i])) \n",
    "os.chdir(\"/home/hades/codes/leiden/cold/case_study\")    \n",
    "np.save('sunny_match.npy',vote)     \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "#feature vote onlyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyy\n",
    "d_pool=np.load('/home/hades/codes/leiden/temp/d_pool_cold.npy')\n",
    "cl_idx=np.load('/home/hades/codes/leiden/temp/cl_idx_cold.npy')\n",
    "\n",
    "d_sunny=[]\n",
    "counter=0\n",
    "\n",
    "os.chdir(\"/home/hades/codes/leiden/cold/dataset_sunny/\")\n",
    "for j in range(0,len(final_Clusters)):\n",
    "    d_sunny.append([])\n",
    "    for i in final_Clusters[j]:\n",
    "\n",
    "        for filename in glob.glob('*.jpeg'):\n",
    "            if int(filename[:-5])==i:\n",
    "                img = cv2.imread(filename,0)\n",
    "                sift=cv2.xfeatures2d.SURF_create(200)\n",
    "    # Find keypoints and descriptors directly\n",
    "                kp, des = sift.detectAndCompute(img,None)\n",
    "                des.any()==[None]\n",
    "                d_sunny[j].append(des)\n",
    "                counter+=1\n",
    "                #print(\"\\n\")\n",
    "    #print(d_sunny)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #print(d_sunny)\n",
    "\n",
    "d_pool_sunny=[]\n",
    "for i in range(0,len(final_Clusters)):\n",
    "    d_pool_sunny.append([])\n",
    "    for j in range(0,len(d_sunny[i])):\n",
    "        #d_pool_sunny[i].append([])\n",
    "        for k in range(0,len(d_sunny[i][j])):\n",
    "            d_pool_sunny[i].append(d_sunny[i][j][k])\n",
    "        \n",
    "        \n",
    "neigh = NearestNeighbors(n_neighbors=1)\n",
    "neigh.fit(np.array(d_pool)) \n",
    "print('i am here!')\n",
    "match=[]\n",
    "#for i in range(0,len(best_frame)):\n",
    "#    print('loop',i)\n",
    "#    match.append(neigh.kneighbors(np.asarray(features[i])))#.reshape(1, -1))\n",
    "#    print(match[i])\n",
    "vote=[]\n",
    "idx2=[]\n",
    "print(cl_idx)\n",
    "#print(idx2)\n",
    "for i in range(0,len(final_Clusters)):\n",
    "    match=neigh.kneighbors(np.asarray(d_pool_sunny[i]))#.reshape(1, -1))\n",
    "    #print(match)\n",
    "    vote.append([])\n",
    "    for j in range(0,len(match[1])):\n",
    "        for x in range(0,len(cl_idx)):\n",
    "            if match[1][j]<cl_idx[x]:\n",
    "                vote[i].append(x)\n",
    "                break\n",
    "def most_frequent(List): \n",
    "    dict = {} \n",
    "    count, itm = 0, '' \n",
    "    for item in reversed(List): \n",
    "        dict[item] = dict.get(item, 0) + 1\n",
    "        if dict[item] >= count : \n",
    "            count, itm = dict[item], item \n",
    "    return(itm) \n",
    "  \n",
    "\n",
    "for i in range(0,len(vote)):\n",
    "    print(most_frequent(vote[i])) \n",
    "\n",
    "#print(vote[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'any'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-f3ac46b36be8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# Find keypoints and descriptors directly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                 \u001b[0mkp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msift\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetectAndCompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m                 \u001b[0mdes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m                 \u001b[0md_night\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                 \u001b[0mcounter\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'any'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import glob\n",
    "#feature vote onlyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyy\n",
    "d_pool=np.load('/home/hades/codes/leiden/temp/d_pool_cold.npy')\n",
    "cl_idx=np.load('/home/hades/codes/leiden/temp/cl_idx_cold.npy')\n",
    "\n",
    "d_night=[]\n",
    "counter=0\n",
    "\n",
    "os.chdir(\"/home/hades/codes/leiden/cold/dataset_night/\")\n",
    "for j in range(0,len(final_Clusters)):\n",
    "    d_night.append([])\n",
    "    for i in final_Clusters[j]:\n",
    "\n",
    "        for filename in glob.glob('*.jpeg'):\n",
    "            if int(filename[:-5])==i:\n",
    "                img = cv2.imread(filename,0)\n",
    "                sift=cv2.xfeatures2d.SURF_create(200)\n",
    "    # Find keypoints and descriptors directly\n",
    "                kp, des = sift.detectAndCompute(img,None)\n",
    "                des.any()==[None]\n",
    "                d_night[j].append(des)\n",
    "                counter+=1\n",
    "                #print(\"\\n\")\n",
    "    #print(d_sunny)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #print(d_sunny)\n",
    "\n",
    "d_pool_night=[]\n",
    "for i in range(0,len(final_Clusters)):\n",
    "    d_pool_night.append([])\n",
    "    for j in range(0,len(d_night[i])):\n",
    "        #d_pool_sunny[i].append([])\n",
    "        for k in range(0,len(d_night[i][j])):\n",
    "            d_pool_night[i].append(d_night[i][j][k])\n",
    "        \n",
    "        \n",
    "neigh = NearestNeighbors(n_neighbors=1)\n",
    "neigh.fit(np.array(d_pool)) \n",
    "print('i am here!')\n",
    "match=[]\n",
    "#for i in range(0,len(best_frame)):\n",
    "#    print('loop',i)\n",
    "#    match.append(neigh.kneighbors(np.asarray(features[i])))#.reshape(1, -1))\n",
    "#    print(match[i])\n",
    "vote=[]\n",
    "idx2=[]\n",
    "print(cl_idx)\n",
    "#print(idx2)\n",
    "for i in range(0,len(final_Clusters)):\n",
    "    match=neigh.kneighbors(np.asarray(d_pool_night[i]))#.reshape(1, -1))\n",
    "    #print(match)\n",
    "    vote.append([])\n",
    "    for j in range(0,len(match[1])):\n",
    "        for x in range(0,len(cl_idx)):\n",
    "            if match[1][j]<cl_idx[x]:\n",
    "                vote[i].append(x)\n",
    "                break\n",
    "def most_frequent(List): \n",
    "    dict = {} \n",
    "    count, itm = 0, '' \n",
    "    for item in reversed(List): \n",
    "        dict[item] = dict.get(item, 0) + 1\n",
    "        if dict[item] >= count : \n",
    "            count, itm = dict[item], item \n",
    "    return(itm) \n",
    "  \n",
    "\n",
    "for i in range(0,len(vote)):\n",
    "    print(most_frequent(vote[i])) \n",
    "\n",
    "#print(vote[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---TOOLS---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil, os\n",
    "dataset='night'\n",
    "import glob\n",
    "files0=glob.glob(\"/home/hades/Downloads/Datasets/seq1_%s1/std_cam/*.jpeg\"%dataset)\n",
    "files0.sort(reverse=False);\n",
    "print(len(files0))\n",
    "counter5=0\n",
    "os.mkdir('/home/hades/codes/leiden/cold/dataset_%s/'%dataset)\n",
    "for i in files0:\n",
    "    shutil.copy(\"%s\"%i, '/home/hades/codes/leiden/cold/dataset_%s/%d.jpeg'%(dataset,counter5))\n",
    "    counter5+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(d_pool_night[294])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argwhere(np.asarray(final_Clusters[0])==1225)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter=0\n",
    "print(night_best_frame)\n",
    "print(sunny_best_frame)\n",
    "#print(cloudy_best_frame)\n",
    "files0=glob.glob(\"/home/hades/Downloads/Datasets/seq1_night1/std_cam/*.jpeg\")\n",
    "files0.sort(reverse=False);\n",
    "for i in night_best_frame:\n",
    "    counter+=1\n",
    "    img=cv2.imread(files0[i])\n",
    "    cv2.imshow(\"cluster %s frame %s\"%(counter-1,str(i)),img)\n",
    "    \n",
    "cv2.waitKey(0) \n",
    "cv2.destroyAllWindows() \n",
    "files0=glob.glob(\"/home/hades/Downloads/Datasets/seq1_sunny1/std_cam/*.jpeg\")\n",
    "files0.sort(reverse=False);\n",
    "counter=0\n",
    "for i in sunny_best_frame:\n",
    "    counter+=1\n",
    "    img=cv2.imread(files0[i])\n",
    "    cv2.imshow(\"cluster %s frame %s\"%(counter-1,str(i)),img)\n",
    "    \n",
    "cv2.waitKey(0) \n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('/home/hades/codes/leiden/cold/vote_night.npy' ,final_Clusters, allow_pickle=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python_libs_3",
   "language": "python",
   "name": "libs_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}